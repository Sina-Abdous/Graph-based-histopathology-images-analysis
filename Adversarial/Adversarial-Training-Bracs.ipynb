{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj6EnzRyAY5q"
      },
      "source": [
        "# **Adversarial-Training-Bracs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej3H_oMmAx3C",
        "outputId": "77fdc883-a3f3-4489-a943-39a3e95b8ee8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/hila-chefer/Transformer-Explainability.git\n",
        "\n",
        "import os\n",
        "os.chdir(f'./Transformer-Explainability')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install einops\n",
        "!pip install torchattacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdJ4YOiTBtAz",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from torchattacks.attacks.apgd import APGD \n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from torchattacks import PGD\n",
        "from torchvision.utils import save_image\n",
        "from baselines.ViT.ViT_LRP import deit_base_patch16_224 as vit_LRP\n",
        "#from baselines.ViT.ViT_LRP import vit_base_patch16_224 as vit_LRP\n",
        "from baselines.ViT.ViT_explanation_generator import LRP\n",
        "from baselines.ViT.ViT_LRP import VisionTransformer\n",
        "from baselines.ViT.helpers import load_pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtqMdXdTEKAP",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Imagenet class indices to names\n",
        "%%capture\n",
        "CLS2IDX = {0: '0_N',\n",
        " 1: '1_PB',\n",
        " 2: '2_UDH',\n",
        " 3: '3_ADH',\n",
        " 4: '4_FEA',\n",
        " 5: '5_DCIS',\n",
        " 6: '6_IC'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXG4UvzYwp6U",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def safe_divide(a, b):\n",
        "    den = b.clamp(min=1e-9) + b.clamp(max=1e-9)\n",
        "    den = den + den.eq(0).type(den.type()) * 1e-9\n",
        "    return a / den * b.ne(0).type(b.type())\n",
        "    \n",
        "def forward_hook(self, input, output):\n",
        "    if type(input[0]) in (list, tuple):\n",
        "        self.X = []\n",
        "        for i in input[0]:\n",
        "            x = i.detach()\n",
        "            x.requires_grad = True\n",
        "            self.X.append(x)\n",
        "    else:\n",
        "        self.X = input[0].detach()\n",
        "        self.X.requires_grad = True\n",
        "\n",
        "    self.Y = output\n",
        "\n",
        "class RelProp(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RelProp, self).__init__()\n",
        "        # if not self.training:\n",
        "        self.register_forward_hook(forward_hook)\n",
        "\n",
        "    def gradprop(self, Z, X, S):\n",
        "        C = torch.autograd.grad(Z, X, S, retain_graph=True)\n",
        "        return C\n",
        "\n",
        "    def relprop(self, R, alpha):\n",
        "        return R\n",
        "\n",
        "class IndexSelect(RelProp):\n",
        "    def forward(self, inputs, dim, indices):\n",
        "        self.__setattr__('dim', dim)\n",
        "        self.__setattr__('indices', indices)\n",
        "\n",
        "        return torch.index_select(inputs, dim, indices)\n",
        "\n",
        "    def relprop(self, R, alpha):\n",
        "        Z = self.forward(self.X, self.dim, indices)\n",
        "        S = safe_divide(R, Z)\n",
        "        C = self.gradprop(Z, self.X, S)\n",
        "\n",
        "        if torch.is_tensor(self.X) == False:\n",
        "            outputs = []\n",
        "            outputs.append(self.X[0] * C[0])\n",
        "            outputs.append(self.X[1] * C[1])\n",
        "        else:\n",
        "            outputs = self.X * (C[0])\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5QP4Gq6_0iYy",
        "outputId": "42dedf50-abb6-41a6-dec7-e201ecc3d5a7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#Download dataset\n",
        "!wget -c -r ftp://histoimage.na.icar.cnr.it/BRACS_RoI/previous_versions/Version1_MedIA/Images\n",
        "#transform downloaded dataset to 224*224 and save it in google Drive\n",
        "'''\n",
        "code\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkYD-95il9b9",
        "outputId": "b4c3dd93-3ddc-4542-8bb6-c73c80a33291",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiLs9m9kYxNu",
        "outputId": "c9c7e833-a190-45d1-9d70-a01520e4a273",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#unzip saved images into current drive account (I had to use different accounts due to google colab's limitation. Actulally notebook sharing wasn't working neither :)) )\n",
        "!unzip -u \"/content/drive/MyDrive/Images-20221110T104340Z-001.zip\" -d \"/content/drive/My Drive/Bracs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gy4m6GQymTCf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFlrytmTmb9C",
        "outputId": "e3931f4b-ab08-420a-ddb0-01db9bb80be3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1_PB\n",
            "2_UDH\n",
            "5_DCIS\n",
            "3_ADH\n",
            "0_N\n",
            "6_IC\n",
            "4_FEA\n",
            "(3163,)\n",
            "4_FEA\n",
            "0_N\n",
            "3_ADH\n",
            "5_DCIS\n",
            "1_PB\n",
            "2_UDH\n",
            "6_IC\n",
            "(602,)\n"
          ]
        }
      ],
      "source": [
        "def prepareDatasets(direction, share=1):\n",
        "    cnt = 0\n",
        "    dataset = list()\n",
        "\n",
        "    for folder in os.listdir(direction):\n",
        "        print(folder)\n",
        "\n",
        "        if share != 1:\n",
        "          randomlist = []\n",
        "          for i in range(0,int ( share * len(os.listdir(direction + f'/{folder}')))):\n",
        "            n = random.randint(1,len(os.listdir(direction + f'/{folder}')))\n",
        "            randomlist.append(n)\n",
        "\n",
        "        cnt = 0\n",
        "        for image in os.listdir(direction + f'/{folder}'):\n",
        "\n",
        "            if share != 1:\n",
        "              if cnt not in randomlist:\n",
        "                cnt += 1\n",
        "                continue\n",
        "\n",
        "            im= Image.open(os.path.join(direction + f'/{folder}',image))\n",
        "            try:\n",
        "\n",
        "              img = transform(im)\n",
        "\n",
        "              label = torch.tensor(int(folder[0]))\n",
        "              data = {\"image\": img, \"label\": label}\n",
        "              dataset.append(data)\n",
        "              cnt += 1\n",
        "            except (OSError):\n",
        "              print(\"shit\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/Bracs/Images/Train\"\n",
        "val_dir = \"/content/drive/MyDrive/Bracs/Images/Validation\"\n",
        "\n",
        "train_dataset = prepareDatasets(train_dir)\n",
        "print(np.shape(train_dataset))\n",
        "#For example, prepareDatasets(train_dir, share=0.3) picks 0.3 of images\n",
        "\n",
        "validation_dataset = prepareDatasets(val_dir)\n",
        "print(np.shape(validation_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUl5s9mLsjRk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "data = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=20,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        " )\n",
        "\n",
        "\n",
        "data_val = DataLoader(\n",
        "    validation_dataset,\n",
        "    batch_size=20,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429,
          "referenced_widgets": [
            "de6a32879d57436b9f83f0ae14c2439d",
            "d27b95a536fd4cc6a15e8092bb71ee8e",
            "a4f8475409a14819b36254eb06b92248",
            "2d62ae111cb64554ab0fb4a41e78c558",
            "50ecf024aabf4b56be02c7f5bd272271",
            "24bc60e17fcf47f5bc5ccbba251ca733",
            "06d9b0d86f834bb6849f7a8b2db1d5af",
            "172517b6bc414a2e8c8ef3a6927e5c9e",
            "4aae03083fbe4cd88d383c48927011ba",
            "e67c641f280b4bdea41ab8c698f1dfe3",
            "957daca15d3147b2a1f4a630ca97eb1e"
          ]
        },
        "id": "namOYUhyAxGo",
        "outputId": "7c4a9198-01fe-426e-cf93-dc585e0c8a8f",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model = vit_LRP(pretrained=True).cuda()\n",
        "\n",
        "model.head.out_features = 7\n",
        "model.pool = IndexSelect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93Nswg0--70A",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def _cfg(url='', **kwargs):\n",
        "    return {\n",
        "        'url': url,\n",
        "        'num_classes': 7, 'input_size': (3, 224, 224), 'pool_size': None,\n",
        "        'crop_pct': .9, 'interpolation': 'bicubic',\n",
        "        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n",
        "        **kwargs\n",
        "    }\n",
        "\n",
        "\n",
        "default_cfgs = {\n",
        "    # patch models\n",
        "    'vit_small_patch16_224': _cfg(\n",
        "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/vit_small_p16_224-15ec54c9.pth',\n",
        "    ),\n",
        "    'vit_base_patch16_224': _cfg(\n",
        "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_224-80ecf9dd.pth',\n",
        "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
        "    ),\n",
        "    'vit_large_patch16_224': _cfg(\n",
        "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p16_224-4ee7a4dc.pth',\n",
        "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "}\n",
        "\n",
        "def _conv_filter(state_dict, patch_size=16):\n",
        "    \"\"\" convert patch embedding weight from manual patchify + linear proj to conv\"\"\"\n",
        "    out_dict = {}\n",
        "    for k, v in state_dict.items():\n",
        "        if 'patch_embed.proj.weight' in k:\n",
        "            v = v.reshape((v.shape[0], 3, patch_size, patch_size))\n",
        "        out_dict[k] = v\n",
        "    return out_dict\n",
        "\n",
        "def vit_base_patch16_224_7class(pretrained=False, **kwargs):\n",
        "    model = VisionTransformer(\n",
        "        patch_size=16, num_classes=7, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True, **kwargs)\n",
        "    model.default_cfg = default_cfgs['vit_base_patch16_224']\n",
        "    if pretrained:\n",
        "        load_pretrained(\n",
        "            model, num_classes=model.num_classes, in_chans=kwargs.get('in_chans', 3), filter_fn=_conv_filter)\n",
        "    return model\n",
        "\n",
        "def vit_large_patch16_224_7class(pretrained=False, **kwargs):\n",
        "    model = VisionTransformer(\n",
        "        patch_size=16, num_classes=7, embed_dim=1024, depth=24, num_heads=16, mlp_ratio=4, qkv_bias=True, **kwargs)\n",
        "    model.default_cfg = default_cfgs['vit_large_patch16_224']\n",
        "    if pretrained:\n",
        "        load_pretrained(model, num_classes=model.num_classes, in_chans=kwargs.get('in_chans', 3))\n",
        "    return model\n",
        "\n",
        "def deit_base_patch16_224_7class(pretrained=False, **kwargs):\n",
        "    model = VisionTransformer(\n",
        "        patch_size=16, num_classes=7, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True, **kwargs)\n",
        "    model.default_cfg = _cfg()\n",
        "    if pretrained:\n",
        "        checkpoint = torch.hub.load_state_dict_from_url(\n",
        "            url=\"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\",\n",
        "            map_location=\"cpu\", check_hash=True\n",
        "        )\n",
        "        model.load_state_dict(checkpoint[\"model\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLK1JEhm_ic2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#model = deit_base_patch16_224_7class(pretrained=False).cuda()\n",
        "#model = vit_base_patch16_224_7class(pretrained=False).cuda()\n",
        "#model = torch.load('/content/drive/MyDrive/Models_saves/model5.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqQjN1mGvm6h",
        "outputId": "6f642a3d-0a27-4c54-fb5b-362192034cda",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TjB6UrpzC1N",
        "outputId": "f378b82e-a91f-434f-a682-2f152f5a38c6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "attack = APGD(model, eps=(6/255), norm='L2', steps = 10)\n",
        "\n",
        "print(attack.eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_a60jnzBT38",
        "outputId": "9ad0cec0-5537-4e95-e024-f431ea14f669",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#This cell is for saving noises and is unnecessary \n",
        "with tqdm.tqdm(enumerate(data), total=len(data)) as pbar:\n",
        "    ad_images = torch.Tensor(list())\n",
        "    cnt = 0\n",
        "    for i, x in pbar:\n",
        "      \n",
        "      cnt+=1\n",
        "      image = x[\"image\"]\n",
        "      label = x[\"label\"]\n",
        "      image = image.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      ad_images = attack(image, label)\n",
        "\n",
        "      result = torch.cat((image, ad_images))\n",
        "      result = torch.cat((result, ad_images - image))\n",
        "      save_image(result, fp = f'/content/out{cnt}.png' ,nrow = len(label), scale_each=True, normalize=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9lid9GEgBab",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=4e-3, momentum=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pStoo6Obfp_A",
        "outputId": "847dae54-206b-4e2a-b9d1-28e94e295501",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def train_val(mode, adv, losses, epoch):\n",
        "\n",
        "    #torch.cuda.empty_cache()\n",
        "    loss_sum = 0\n",
        "    true = 0\n",
        "    all = 0\n",
        "    class0_true = 0\n",
        "    class0_all = 0\n",
        "    class1_true = 0\n",
        "    class1_all = 0\n",
        "    class2_true = 0\n",
        "    class2_all = 0\n",
        "    class3_true = 0\n",
        "    class3_all = 0\n",
        "    class4_true = 0\n",
        "    class4_all = 0\n",
        "    class5_true =  0\n",
        "    class5_all = 0\n",
        "    class6_true = 0\n",
        "    class6_all = 0\n",
        "\n",
        "    i = 0\n",
        "    with tqdm.tqdm(enumerate(data), total=len(data)) as pbar:\n",
        "        ad_images = torch.Tensor(list())\n",
        "\n",
        "        for i, x in pbar:\n",
        "            \n",
        "            image = x[\"image\"]\n",
        "            label = x[\"label\"]\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            if adv and ((mode == 'val') or (mode == 'train' and epoch > 1)):\n",
        "              ad_images = attack(image, label)\n",
        "            \n",
        "            if mode == 'train':\n",
        "              model.train()\n",
        "\n",
        "            if adv and ((mode == 'val') or (mode == 'train' and epoch > 1)):\n",
        "              p = model(ad_images)\n",
        "            else:\n",
        "              p = model(image)\n",
        "\n",
        "            loss = criterion(p[:, :7], label)\n",
        "            loss_sum += float(loss)*20\n",
        "\n",
        "            predictions = p[:, :7].argmax(-1)\n",
        "            all += float(len(predictions))\n",
        "            class0_all += float((label == 0).sum())\n",
        "            class1_all += float((label == 1).sum())\n",
        "            class2_all += float((label == 2).sum())\n",
        "            class3_all += float((label == 3).sum())\n",
        "            class4_all += float((label == 4).sum())\n",
        "            class5_all += float((label == 5).sum())\n",
        "            class6_all += float((label == 6).sum())\n",
        "            true += float((predictions == label).sum())\n",
        "\n",
        "            class0_pred = (predictions == 0)\n",
        "            class0_label = (label == 0)\n",
        "            class0_true += float((torch.logical_and(class0_pred,class0_label)).sum())\n",
        "\n",
        "            class1_pred = (predictions == 1)\n",
        "            class1_label = (label == 1)\n",
        "            class1_true += float((torch.logical_and(class1_pred,class1_label)).sum())\n",
        "\n",
        "            class2_pred = (predictions == 2)\n",
        "            class2_label = (label == 2)\n",
        "            class2_true += float((torch.logical_and(class2_pred,class2_label)).sum())\n",
        "\n",
        "            class3_pred = (predictions == 3)\n",
        "            class3_label = (label == 3)\n",
        "            class3_true += float((torch.logical_and(class3_pred,class3_label)).sum())\n",
        "\n",
        "\n",
        "            class4_pred = (predictions == 4)\n",
        "            class4_label = (label == 4)\n",
        "            class4_true += float((torch.logical_and(class4_pred,class4_label)).sum())\n",
        "\n",
        "            class5_pred = (predictions == 5)\n",
        "            class5_label = (label == 5)\n",
        "            class5_true += float((torch.logical_and(class5_pred,class5_label)).sum())\n",
        "\n",
        "\n",
        "            class6_pred = (predictions == 6)\n",
        "            class6_label = (label == 6)\n",
        "            class6_true += float((torch.logical_and(class6_pred,class6_label)).sum())\n",
        "\n",
        "            del image\n",
        "            del label\n",
        "\n",
        "            pbar.set_description(f'Acc: {true * 100. / all:.2f}%')\n",
        "            \n",
        "            if mode == 'train':\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "        if (class0_all > 0): print(f'Acc class0: {class0_true * 100. / class0_all:.2f}%')\n",
        "        if (class1_all > 0): print(f'Acc class1: {class1_true * 100. / class1_all:.2f}%')\n",
        "        if (class2_all > 0): print(f'Acc class2: {class2_true * 100. / class2_all:.2f}%')\n",
        "        if (class3_all > 0): print(f'Acc class3: {class3_true * 100. / class3_all:.2f}%')\n",
        "        if (class4_all > 0): print(f'Acc class4: {class4_true * 100. / class4_all:.2f}%')\n",
        "        if (class5_all > 0): print(f'Acc class5: {class5_true * 100. / class5_all:.2f}%')\n",
        "        if (class6_all > 0): print(f'Acc class6: {class6_true * 100. / class6_all:.2f}%')\n",
        "\n",
        "    losses.append(loss_sum)\n",
        "    if mode == 'train':\n",
        "      torch.save(model.state_dict(), f'/content/drive/MyDrive/Models_saves/model_state_dict{epoch}.pth')\n",
        "    \n",
        "    state = 'train' if mode == 'train' else ('adversarial validation' if adv else 'validation')\n",
        "    print(f'{state} : Epoch {epoch} \\n')\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "num_epochs=15\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "adv_val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_losses = train_val('train', True, train_losses, epoch)\n",
        "    val_losses = train_val('val', False, val_losses, epoch)\n",
        "    adv_val_losses = train_val('val', True, adv_val_losses, epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1J1LV2NLEXez",
        "outputId": "f111191e-ff70-48af-baac-4ee9d62f4325",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#Plotting losses \n",
        "epochs = np.arange(15)\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(20, 30))\n",
        "ax1.set_title(\"Training loss\")\n",
        "ax1.plot(epochs, train_losses)\n",
        "\n",
        "ax2.set_title(\"Normal Validation loss\")\n",
        "ax2.plot(epochs, val_losses)\n",
        "\n",
        "ax3.set_title(\"Adversarial Validation loss\")\n",
        "ax3.plot(epochs, adv_val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7Bh1k_cmOJ8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/Models_saves/model_state_dict2.pth'))\n",
        "#torch.save(model.state_dict(), '/content/drive/MyDrive/Models_saves/model_state_dict2.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "pGpRDaeEWIW2",
        "outputId": "48f12026-d4af-4d4a-fdaf-3f8c98f79dae",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# create heatmap from mask on image\n",
        "def show_cam_on_image(img, mask):\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
        "    heatmap = np.float32(heatmap) / 255\n",
        "    cam = heatmap + np.float32(img)\n",
        "    cam = cam / np.max(cam)\n",
        "    return cam\n",
        "\n",
        "attribution_generator = LRP(model)\n",
        "\n",
        "def generate_visualization(original_image, class_index=None):\n",
        "    transformer_attribution = attribution_generator.generate_LRP(original_image.unsqueeze(0).cuda(), method=\"transformer_attribution\", index=class_index).detach()\n",
        "    transformer_attribution = transformer_attribution.reshape(1, 1, 14, 14)\n",
        "    transformer_attribution = torch.nn.functional.interpolate(transformer_attribution, scale_factor=16, mode='bilinear')\n",
        "    transformer_attribution = transformer_attribution.reshape(224, 224).cuda().data.cpu().numpy()\n",
        "    transformer_attribution = (transformer_attribution - transformer_attribution.min()) / (transformer_attribution.max() - transformer_attribution.min())\n",
        "    image_transformer_attribution = original_image.permute(1, 2, 0).data.cpu().numpy()\n",
        "    image_transformer_attribution = (image_transformer_attribution - image_transformer_attribution.min()) / (image_transformer_attribution.max() - image_transformer_attribution.min())\n",
        "    vis = show_cam_on_image(image_transformer_attribution, transformer_attribution)\n",
        "    vis =  np.uint8(255 * vis)\n",
        "    vis = cv2.cvtColor(np.array(vis), cv2.COLOR_RGB2BGR)\n",
        "    return vis\n",
        "\n",
        "def print_top_classes(predictions, **kwargs):    \n",
        "    # Print Top-5 predictions\n",
        "    prob = torch.softmax(predictions, dim=1)\n",
        "    class_indices = predictions.data.topk(5, dim=1)[1][0].tolist()\n",
        "    max_str_len = 0\n",
        "    class_names = []\n",
        "    for cls_idx in class_indices:\n",
        "        class_names.append(CLS2IDX[cls_idx])\n",
        "        if len(CLS2IDX[cls_idx]) > max_str_len:\n",
        "            max_str_len = len(CLS2IDX[cls_idx])\n",
        "    \n",
        "    print('Top 5 classes:')\n",
        "    for cls_idx in class_indices:\n",
        "        output_string = '\\t{} : {}'.format(cls_idx, CLS2IDX[cls_idx])\n",
        "        output_string += ' ' * (max_str_len - len(CLS2IDX[cls_idx])) + '\\t\\t'\n",
        "        output_string += 'value = {:.3f}\\t prob = {:.1f}%'.format(predictions[0, cls_idx], 100 * prob[0, cls_idx])\n",
        "        print(output_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "8TmzTuecWg0p",
        "outputId": "21f63a99-dd6f-4c73-dc27-3a96c18d9e20",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def drawHeatmap(direction, index):\n",
        "        \n",
        "    for image in os.listdir(direction):\n",
        "\n",
        "        image= Image.open(os.path.join(direction,image))\n",
        "\n",
        "        transformed_image = transform(image)\n",
        "\n",
        "        fig, axs = plt.subplots(1, 3)\n",
        "        axs[0].imshow(image)\n",
        "        axs[0].axis('off')\n",
        "\n",
        "        output = model(transformed_image.unsqueeze(0).cuda())\n",
        "\n",
        "        # generate visualization for the predicted class\n",
        "        predicted = generate_visualization(transformed_image)\n",
        "\n",
        "        # generate visualization for expected(index) class\n",
        "        expected = generate_visualization(transformed_image, class_index=index)\n",
        "\n",
        "        axs[1].imshow(predicted)\n",
        "        axs[1].axis('off')\n",
        "        axs[2].imshow(expected)\n",
        "        axs[2].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwK_GO6ZpUe5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "val_dir0 = \"/content/drive/MyDrive/Bracs/Images/Validation/0_N\"\n",
        "val_dir1 = \"/content/drive/MyDrive/Bracs/Images/Validation/1_PB\"\n",
        "val_dir2 = \"/content/drive/MyDrive/Bracs/Images/Validation/2_UDH\"\n",
        "val_dir3 = \"/content/drive/MyDrive/Bracs/Images/Validation/3_ADH\"\n",
        "val_dir4 = \"/content/drive/MyDrive/Bracs/Images/Validation/4_FEA\"\n",
        "val_dir5 = \"/content/drive/MyDrive/Bracs/Images/Validation/5_DCIS\"\n",
        "val_dir6 = \"/content/drive/MyDrive/Bracs/Images/Validation/6_IC\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "drawHeatmap(val_dir0, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "drawHeatmap(val_dir1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "drawHeatmap(val_dir2, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "drawHeatmap(val_dir3, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "drawHeatmap(val_dir4, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "drawHeatmap(val_dir5, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "drawHeatmap(val_dir6, 6)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02823f9a34984b23a8d7835772d6ca39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06d9b0d86f834bb6849f7a8b2db1d5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "112b95bde52c4e83801de8f9874e6554": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "172517b6bc414a2e8c8ef3a6927e5c9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24bc60e17fcf47f5bc5ccbba251ca733": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d62ae111cb64554ab0fb4a41e78c558": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e67c641f280b4bdea41ab8c698f1dfe3",
            "placeholder": "​",
            "style": "IPY_MODEL_957daca15d3147b2a1f4a630ca97eb1e",
            "value": " 330M/330M [00:04&lt;00:00, 82.6MB/s]"
          }
        },
        "4aae03083fbe4cd88d383c48927011ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50ecf024aabf4b56be02c7f5bd272271": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59622e31289949d18b78c62334ab1f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d999d1bdb1a74fcba642d0ca3bcf2076",
              "IPY_MODEL_c9179a8d49b842219ef04d6c0050cd3c",
              "IPY_MODEL_66430c6ffc23498a9d564c4b8409446d"
            ],
            "layout": "IPY_MODEL_6f97dd6d1ff24d39a0f979d98ac3f039"
          }
        },
        "66430c6ffc23498a9d564c4b8409446d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_112b95bde52c4e83801de8f9874e6554",
            "placeholder": "​",
            "style": "IPY_MODEL_ac53711c2c9e4497acac3346d09abfe0",
            "value": " 330M/330M [58:57&lt;00:00, 98.0kB/s]"
          }
        },
        "6f97dd6d1ff24d39a0f979d98ac3f039": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d25f3fd52c945a6b625eaca655779c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957daca15d3147b2a1f4a630ca97eb1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4f8475409a14819b36254eb06b92248": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_172517b6bc414a2e8c8ef3a6927e5c9e",
            "max": 346319111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4aae03083fbe4cd88d383c48927011ba",
            "value": 346319111
          }
        },
        "a54ee23ee5724fe19fe855569cd32d70": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac53711c2c9e4497acac3346d09abfe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9179a8d49b842219ef04d6c0050cd3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d25f3fd52c945a6b625eaca655779c0",
            "max": 346319111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02823f9a34984b23a8d7835772d6ca39",
            "value": 346319111
          }
        },
        "d27b95a536fd4cc6a15e8092bb71ee8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24bc60e17fcf47f5bc5ccbba251ca733",
            "placeholder": "​",
            "style": "IPY_MODEL_06d9b0d86f834bb6849f7a8b2db1d5af",
            "value": "100%"
          }
        },
        "d999d1bdb1a74fcba642d0ca3bcf2076": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a54ee23ee5724fe19fe855569cd32d70",
            "placeholder": "​",
            "style": "IPY_MODEL_fcb8680496174e4f8b388cf6c7ad7e48",
            "value": "100%"
          }
        },
        "de6a32879d57436b9f83f0ae14c2439d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d27b95a536fd4cc6a15e8092bb71ee8e",
              "IPY_MODEL_a4f8475409a14819b36254eb06b92248",
              "IPY_MODEL_2d62ae111cb64554ab0fb4a41e78c558"
            ],
            "layout": "IPY_MODEL_50ecf024aabf4b56be02c7f5bd272271"
          }
        },
        "e67c641f280b4bdea41ab8c698f1dfe3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb8680496174e4f8b388cf6c7ad7e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
